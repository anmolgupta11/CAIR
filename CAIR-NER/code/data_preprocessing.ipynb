{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AHKb4tEUyakr"
   },
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ogGoM_oLy4bD"
   },
   "source": [
    "### **Training** **Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XEGuoT6syER2"
   },
   "outputs": [],
   "source": [
    "import pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "awX3isyXzc55"
   },
   "source": [
    "**Loading *training.abstracts* file from the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ubOLiMRhzKEl"
   },
   "outputs": [],
   "source": [
    "dataframe = pandas.read_csv(\"training.abstracts.txt\",delimiter=\"\\t\")\n",
    "\n",
    "dataframe.to_csv(\"table.abstracts.csv\", encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iB42MLTEzKMf"
   },
   "outputs": [],
   "source": [
    "ID=[]\n",
    "Title1=[]\n",
    "Paragraph=[]\n",
    "import csv\n",
    "with open('table.abstracts.csv','rt')as f:\n",
    "    data = csv.reader(f)\n",
    "    for row in data:\n",
    "        ID.append(row[0])\n",
    "        Title1.append(row[1])\n",
    "        Paragraph.append(row[2])\n",
    "        #print(row[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IptDc5oWzjaC"
   },
   "source": [
    "**Loading *training.annotations* file from the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e2xS2CYwzKQb"
   },
   "outputs": [],
   "source": [
    "dataframe = pandas.read_csv(\"training.annotations.txt\",delimiter=\"\\t\")\n",
    "\n",
    "dataframe.to_csv(\"table.training.annotations.csv\", encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JYhRN6UwzKhG"
   },
   "outputs": [],
   "source": [
    "tParaID=[]\n",
    "tTitle=[]\n",
    "tstart=[]\n",
    "tend=[]\n",
    "tnames=[]\n",
    "tTags=[]\n",
    "import csv\n",
    "with open('table.training.annotations.csv','rt')as f:\n",
    "    data = csv.reader(f)\n",
    "    for row in data:\n",
    "        tParaID.append(row[0])\n",
    "        tTitle.append(row[1])\n",
    "        tstart.append(row[2])\n",
    "        tend.append(row[3])\n",
    "        tnames.append(row[4])\n",
    "        tTags.append(row[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sUb5megZzrCw"
   },
   "source": [
    "**Tokenizing the text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vkYkZ2jSzKfB"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "f= open(\"training25.txt\",\"w+\")\n",
    "for i in range(len(tnames)):\n",
    "    strc=tnames[i]\n",
    "    strt=tTags[i]\n",
    "    b=int(tstart[i])\n",
    "      #c=int(tend[i])\n",
    "    count=0\n",
    "    for j in range(len(strc)):\n",
    "    if strc[j]==\" \":\n",
    "        count=count+1\n",
    "    if count==0:\n",
    "        r=tParaID[i]+\"\\t\"+tTitle[i]+\"\\t\"+tstart[i]+\"\\t\"+tend[i]+\"\\t\"+strc+\"\\tB-\"+strt+\"\\n\"\n",
    "        f.write(r)\n",
    "    if count>0:\n",
    "        #nltk_tokens = nltk.word_tokenize(str)\n",
    "        nltk_tokens=WhitespaceTokenizer().tokenize(strc)\n",
    "        for k in range(len(nltk_tokens)):\n",
    "            if(k==0):\n",
    "                c=b+len(nltk_tokens[0])\n",
    "                r=tParaID[i]+\"\\t\"+tTitle[i]+\"\\t\"\n",
    "                f.write(r)\n",
    "                r=str(b)\n",
    "                f.write(r)\n",
    "                r=\"\\t\"\n",
    "                f.write(r)\n",
    "                r=str(c)\n",
    "                f.write(r)\n",
    "                r=\"\\t\"+nltk_tokens[0]+\"\\tB-\"+strt+\"\\n\"\n",
    "                b=c+1\n",
    "                f.write(r)\n",
    "            else:\n",
    "                c=b+len(nltk_tokens[k])\n",
    "                r=tParaID[i]+\"\\t\"+tTitle[i]+\"\\t\"\n",
    "                f.write(r)\n",
    "                r=str(b)\n",
    "                f.write(r)\n",
    "                r=\"\\t\"\n",
    "                f.write(r)\n",
    "                r=str(c)\n",
    "                f.write(r)\n",
    "                r=\"\\t\"+nltk_tokens[k]+\"\\tI-\"+strt+\"\\n\"\n",
    "                b=c+1\n",
    "                f.write(r)\n",
    "        \n",
    "f.close()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MZ9YKB1_zKdi"
   },
   "outputs": [],
   "source": [
    "dataframe = pandas.read_csv(\"training25.txt\",delimiter=\"\\t\")\n",
    "\n",
    "dataframe.to_csv(\"table.training25.csv\", encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "50vrVFtHzKcQ"
   },
   "outputs": [],
   "source": [
    "ntParaID=[]\n",
    "ntTitle=[]\n",
    "ntstart=[]\n",
    "ntend=[]\n",
    "ntnames=[]\n",
    "ntTags=[]\n",
    "import csv\n",
    "with open('table.training25.csv','rt')as f:\n",
    "    data = csv.reader(f)\n",
    "    for row in data:\n",
    "        ntParaID.append(row[0])\n",
    "        ntTitle.append(row[1])\n",
    "        ntstart.append(row[2])\n",
    "        ntend.append(row[3])\n",
    "        ntnames.append(row[4])\n",
    "        ntTags.append(row[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qxF0BDUtz-VI"
   },
   "source": [
    "**Separating out the tags**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0C2Q8WJuzKbL"
   },
   "outputs": [],
   "source": [
    "ntTags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W9Pv7WrM0GqV"
   },
   "source": [
    "**Using pivoted binary search to look for the words of *training.annotations* file in *training.abstracts* file** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Wz7wy1-tzKaP"
   },
   "outputs": [],
   "source": [
    "# Python Program to search an element \n",
    "# in a sorted and pivoted array \n",
    "  \n",
    "# Searches an element key in a pivoted \n",
    "# sorted array arrp[] of size n  \n",
    "def pivotedBinarySearch(arr, n, key): \n",
    "  \n",
    "    pivot = findPivot(arr, 0, n-1); \n",
    "    \n",
    "    # If we didn't find a pivot,  \n",
    "    # then array is not rotated at all \n",
    "    if pivot == -1: \n",
    "        return binarySearch(arr, 0, n-1, key); \n",
    "  \n",
    "    # If we found a pivot, then first \n",
    "    # compare with pivot and then \n",
    "    # search in two subarrays around pivot \n",
    "    if arr[pivot] == key: \n",
    "        return pivot \n",
    "    if arr[0] <= key: \n",
    "        return binarySearch(arr, 0, pivot-1, key); \n",
    "    return binarySearch(arr, pivot+1, n-1, key); \n",
    "\n",
    "\n",
    "# Function to get pivot. \n",
    "# For example, for an array  3, 4, 5, 6, 1, 2 it returns 3  (index of 6)\n",
    "    \n",
    "def findPivot(arr, low, high): \n",
    "      \n",
    "    # base cases \n",
    "    if high < low: \n",
    "        return -1\n",
    "    if high == low: \n",
    "        return low \n",
    "      \n",
    "    #low + (high - low)/2; \n",
    "    mid = int((low + high)/2) \n",
    "      \n",
    "    if mid < high and arr[mid] > arr[mid + 1]: \n",
    "        return mid \n",
    "    if mid > low and arr[mid] < arr[mid - 1]: \n",
    "        return (mid-1) \n",
    "    if arr[low] >= arr[mid]: \n",
    "        return findPivot(arr, low, mid-1) \n",
    "    return findPivot(arr, mid + 1, high) \n",
    "  \n",
    "# Standard Binary Search function*/ \n",
    "def binarySearch(arr, low, high, key): \n",
    "  \n",
    "    if high < low: \n",
    "        return -1\n",
    "          \n",
    "    #low + (high - low)/2;     \n",
    "    mid = int((low + high)/2) \n",
    "      \n",
    "    if key == arr[mid]: \n",
    "        return mid\n",
    "    if key > arr[mid]: \n",
    "        return binarySearch(arr, (mid + 1), high, \n",
    "                                            key); \n",
    "    return binarySearch(arr, low, (mid -1), key);\n",
    "        \n",
    "        \n",
    "      \n",
    "        \n",
    "# Program to check above functions\n",
    "\n",
    "arr1=ID \n",
    "n = len(arr1) \n",
    "#f= open(\"training.linebyline.txt\",\"w+\")\n",
    "for i in range(len(ntParaID)):\n",
    "    a=pivotedBinarySearch(arr1, n, ntParaID[i])\n",
    "    if ntTitle[i]=='T':\n",
    "        b=int(ntend[i])\n",
    "        strt=Title1[a]\n",
    "        strt=strt[:b]+\"|\"+strt[b+1:]\n",
    "        Title1[a]=strt\n",
    "        #f.write(Title1[a]) \n",
    "    else:\n",
    "        b=int(ntend[i])\n",
    "        strt=Paragraph[a]\n",
    "        strt=strt[:b]+\"|\"+strt[b+1:]\n",
    "        Paragraph[a]=strt\n",
    "        #f.write(Paragraph[a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rCdEAtjvzKZU"
   },
   "outputs": [],
   "source": [
    "f= open(\"training.linebyline.txt\",\"w+\")\n",
    "for i in range(len(ID)):\n",
    "    f.write(ID[i])\n",
    "    f.write(\"\\t\")\n",
    "    f.write(Title1[i])\n",
    "    f.write(\"\\t\")\n",
    "    f.write(Paragraph[i])\n",
    "    f.write(\"\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kTS7nvz0zKYC"
   },
   "outputs": [],
   "source": [
    "file= open(\"training.finallytagged.txt\",\"w+\")\n",
    "text= open(\"training.linebyline.txt\",\"r\")\n",
    "data=text.read()\n",
    "j=0\n",
    "for i in range(len(data)):\n",
    "    if data[i]==\"|\":\n",
    "        file.write(\" <\")\n",
    "        file.write(ntTags[j])\n",
    "        file.write(\"> \")\n",
    "        j=j+1\n",
    "    else:\n",
    "        file.write(data[i])\n",
    "    \n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1ys0rguczKLg"
   },
   "outputs": [],
   "source": [
    "print(len(ntTags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vPOaeUJyzKG8"
   },
   "outputs": [],
   "source": [
    "j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DSCO_YQDyDL1"
   },
   "source": [
    "### **Development file**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gzPw3xJS0xT_"
   },
   "source": [
    "**Reading the *development.abstracts* file from dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s1qAYLKM0lEP"
   },
   "outputs": [],
   "source": [
    "dataframe = pandas.read_csv(\"development.abstracts.txt\",delimiter=\"\\t\")\n",
    "dataframe.to_csv(\"table.dev.abstracts.csv\", encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zlU08Jbk0mZs"
   },
   "outputs": [],
   "source": [
    "ID=[]\n",
    "Title1=[]\n",
    "Paragraph=[]\n",
    "import csv\n",
    "with open('table.dev.abstracts.csv','rt')as f:\n",
    "    data = csv.reader(f)\n",
    "    for row in data:\n",
    "        ID.append(row[0])\n",
    "        Title1.append(row[1])\n",
    "        Paragraph.append(row[2])\n",
    "        #print(row[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BPhuGlQ204np"
   },
   "source": [
    "**Sort the abstracts file according to Paragraph ID** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q9Bjqu7Q0lzf"
   },
   "outputs": [],
   "source": [
    "## using insertion sort\n",
    "\n",
    "def insertionSort(alist):\n",
    "    for index in range(1,len(alist)):\n",
    "\n",
    "        currentvalue = alist[index]\n",
    "        currentvalue1=Title1[index]\n",
    "        currentvalue2=Paragraph[index]\n",
    "        position = index\n",
    "\n",
    "        while position>0 and alist[position-1]>currentvalue:\n",
    "            alist[position]=alist[position-1]\n",
    "            Title1[position]=Title1[position-1]\n",
    "            Paragraph[position]=Paragraph[position-1]\n",
    "            position = position-1\n",
    "\n",
    "        alist[position]=currentvalue\n",
    "        Title1[position]=currentvalue1\n",
    "        Paragraph[position]=currentvalue2\n",
    "\n",
    "alist = ID\n",
    "insertionSort(alist)\n",
    "print(ID)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XaZF_OV60l4Y"
   },
   "outputs": [],
   "source": [
    "file= open(\"development.abstracts.sort.txt\",\"w+\")\n",
    "for i in range(len(ID)):\n",
    "    file.write(ID[i])\n",
    "    file.write(\"\\t\")\n",
    "    file.write(Title1[i])\n",
    "    file.write(\"\\t\")\n",
    "    file.write(Paragraph[i])\n",
    "    file.write(\"\\n\")\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y3yh7jIb1GYO"
   },
   "source": [
    "**Reading the *development.annotations* file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9XyQsJlm0mAS"
   },
   "outputs": [],
   "source": [
    "dataframe = pandas.read_csv(\"development.annotations.txt\",delimiter=\"\\t\")\n",
    "\n",
    "dataframe.to_csv(\"table.development.annotations.csv\", encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yI-6Mz8P0lwb"
   },
   "outputs": [],
   "source": [
    "dParaID=[]\n",
    "dTitle=[]\n",
    "dstart=[]\n",
    "dend=[]\n",
    "dnames=[]\n",
    "dTags=[]\n",
    "import csv\n",
    "with open('table.development.annotations.csv','rt')as f:\n",
    "    data = csv.reader(f)\n",
    "    for row in data:\n",
    "        dParaID.append(row[0])\n",
    "        dTitle.append(row[1])\n",
    "        dstart.append(row[2])\n",
    "        dend.append(row[3])\n",
    "        dnames.append(row[4])\n",
    "        dTags.append(row[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2o3neg671Rs8"
   },
   "source": [
    "**Sort the annotation file according to Paragraph ID**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rPSJBIjF0lsS"
   },
   "outputs": [],
   "source": [
    "def insertionSort(alist):\n",
    "    for index in range(1,len(alist)):\n",
    "\n",
    "        currentvalue = alist[index]\n",
    "        currentvalue1=dTitle[index]\n",
    "        currentvalue2=dstart[index]\n",
    "        currentvalue3=dend[index]\n",
    "        currentvalue4=dnames[index]\n",
    "        currentvalue5=dTags[index]\n",
    "      \n",
    "        position = index\n",
    "\n",
    "        while position>0 and alist[position-1]>currentvalue:\n",
    "            alist[position]=alist[position-1]\n",
    "            dTitle[position]=dTitle[position-1]\n",
    "            dstart[position]=dstart[position-1]\n",
    "            dend[position]=dend[position-1]\n",
    "            dnames[position]=dnames[position-1]\n",
    "            dTags[position]=dTags[position-1]\n",
    "            position = position-1\n",
    "\n",
    "        alist[position]=currentvalue\n",
    "        dTitle[position]=currentvalue1\n",
    "        dstart[position]=currentvalue2\n",
    "        dend[position]=currentvalue3\n",
    "        dnames[position]=currentvalue4\n",
    "        dTags[position]=currentvalue5\n",
    "\n",
    "alist = dParaID\n",
    "insertionSort(alist)\n",
    "#print(alist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p0tEJ36C0lqq"
   },
   "outputs": [],
   "source": [
    "file= open(\"development.annotations.sort.txt\",\"w+\")\n",
    "for i in range(len(dParaID)):\n",
    "    file.write(dParaID[i])\n",
    "    file.write(\"\\t\")\n",
    "    file.write(dTitle[i])\n",
    "    file.write(\"\\t\")\n",
    "    file.write(dstart[i])\n",
    "    file.write(\"\\t\")\n",
    "    file.write(dend[i])\n",
    "    file.write(\"\\t\")\n",
    "    file.write(dnames[i])\n",
    "    file.write(\"\\t\")\n",
    "    file.write(dTags[i])\n",
    "    file.write(\"\\n\")\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zYTEhfJ-0low"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "f= open(\"development25.txt\",\"w+\")\n",
    "for i in range(len(dnames)):\n",
    "    strc=dnames[i]\n",
    "    strt=dTags[i]\n",
    "    b=int(dstart[i])\n",
    "    #c=int(tend[i])\n",
    "    count=0\n",
    "    for j in range(len(strc)):\n",
    "        if strc[j]==\" \":\n",
    "        count=count+1\n",
    "    if count==0:\n",
    "        r=dParaID[i]+\"\\t\"+dTitle[i]+\"\\t\"+dstart[i]+\"\\t\"+dend[i]+\"\\t\"+strc+\"\\tB-\"+strt+\"\\n\"\n",
    "        f.write(r)\n",
    "    if count>0:\n",
    "        #nltk_tokens = nltk.word_tokenize(str)\n",
    "        nltk_tokens=WhitespaceTokenizer().tokenize(strc)\n",
    "        for k in range(len(nltk_tokens)):\n",
    "            if(k==0):\n",
    "                c=b+len(nltk_tokens[0])\n",
    "                r=dParaID[i]+\"\\t\"+dTitle[i]+\"\\t\"\n",
    "                f.write(r)\n",
    "                r=str(b)\n",
    "                f.write(r)\n",
    "                r=\"\\t\"\n",
    "                f.write(r)\n",
    "                r=str(c)\n",
    "                f.write(r)\n",
    "                r=\"\\t\"+nltk_tokens[0]+\"\\tB-\"+strt+\"\\n\"\n",
    "                b=c+1\n",
    "                f.write(r)\n",
    "            else:\n",
    "                c=b+len(nltk_tokens[k])\n",
    "                r=dParaID[i]+\"\\t\"+dTitle[i]+\"\\t\"\n",
    "                f.write(r)\n",
    "                r=str(b)\n",
    "                f.write(r)\n",
    "                r=\"\\t\"\n",
    "                f.write(r)\n",
    "                r=str(c)\n",
    "                f.write(r)\n",
    "                r=\"\\t\"+nltk_tokens[k]+\"\\tI-\"+strt+\"\\n\"\n",
    "                b=c+1\n",
    "                f.write(r)\n",
    "f.close()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LtlRE4KS1ca8"
   },
   "outputs": [],
   "source": [
    "dataframe = pandas.read_csv(\"development25.txt\",delimiter=\"\\t\")\n",
    "\n",
    "dataframe.to_csv(\"table.development25.csv\", encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UZgZjMzB1dDE"
   },
   "outputs": [],
   "source": [
    "ndParaID=[]\n",
    "ndTitle=[]\n",
    "ndstart=[]\n",
    "ndend=[]\n",
    "ndnames=[]\n",
    "ndTags=[]\n",
    "import csv\n",
    "with open('table.development25.csv','rt')as f:\n",
    "    data = csv.reader(f)\n",
    "    for row in data:\n",
    "        ndParaID.append(row[0])\n",
    "        ndTitle.append(row[1])\n",
    "        ndstart.append(row[2])\n",
    "        ndend.append(row[3])\n",
    "        ndnames.append(row[4])\n",
    "        ndTags.append(row[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "15WFarjU1dF_"
   },
   "outputs": [],
   "source": [
    "# Python Program to search an element \n",
    "# in a sorted and pivoted array \n",
    "  \n",
    "# Searches an element key in a pivoted \n",
    "# sorted array arrp[] of size n  \n",
    "def pivotedBinarySearch(arr, n, key): \n",
    "  \n",
    "    pivot = findPivot(arr, 0, n-1); \n",
    "  \n",
    "    # If we didn't find a pivot,  \n",
    "    # then array is not rotated at all \n",
    "    if pivot == -1: \n",
    "        return binarySearch(arr, 0, n-1, key); \n",
    "  \n",
    "    # If we found a pivot, then first \n",
    "    # compare with pivot and then \n",
    "    # search in two subarrays around pivot \n",
    "    if arr[pivot] == key: \n",
    "        return pivot \n",
    "    if arr[0] <= key: \n",
    "        return binarySearch(arr, 0, pivot-1, key); \n",
    "    return binarySearch(arr, pivot+1, n-1, key); \n",
    "  \n",
    "# Function to get pivot. \n",
    "# For array 3, 4, 5, 6, 1, 2 it returns 3  (index of 6)  \n",
    "def findPivot(arr, low, high): \n",
    "      \n",
    "    # base cases \n",
    "    if high < low: \n",
    "        return -1\n",
    "    if high == low: \n",
    "        return low \n",
    "      \n",
    "    #low + (high - low)/2; \n",
    "    mid = int((low + high)/2) \n",
    "      \n",
    "    if mid < high and arr[mid] > arr[mid + 1]: \n",
    "        return mid \n",
    "    if mid > low and arr[mid] < arr[mid - 1]: \n",
    "        return (mid-1) \n",
    "    if arr[low] >= arr[mid]: \n",
    "        return findPivot(arr, low, mid-1) \n",
    "    return findPivot(arr, mid + 1, high) \n",
    "  \n",
    "# Standard Binary Search function*/ \n",
    "def binarySearch(arr, low, high, key): \n",
    "  \n",
    "    if high < low: \n",
    "        return -1\n",
    "          \n",
    "    #low + (high - low)/2;     \n",
    "    mid = int((low + high)/2) \n",
    "      \n",
    "    if key == arr[mid]: \n",
    "        return mid\n",
    "    if key > arr[mid]: \n",
    "        return binarySearch(arr, (mid + 1), high, \n",
    "                                            key); \n",
    "    return binarySearch(arr, low, (mid -1), key);\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "# Driver program to check above functions */\n",
    "arr1=ID \n",
    "n = len(arr1) \n",
    "#unu=0\n",
    "#f= open(\"training.linebyline.txt\",\"w+\")\n",
    "for i in range(len(ndParaID)):\n",
    "    a=pivotedBinarySearch(arr1, n, ndParaID[i])\n",
    "    if ndTitle[i]=='T':\n",
    "        b=int(ndend[i])\n",
    "        strt=Title1[a]\n",
    "        strt=strt[:b]+\"|\"+strt[b+1:]\n",
    "        Title1[a]=strt\n",
    "        #unu+=1\n",
    "        #f.write(Title1[a]) \n",
    "    else:\n",
    "        b=int(ndend[i])\n",
    "        strt=Paragraph[a]\n",
    "        strt=strt[:b]+\"|\"+strt[b+1:]\n",
    "        Paragraph[a]=strt\n",
    "        #unu+=1\n",
    "        #f.write(Paragraph[a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jUPiBlUa1sCT"
   },
   "outputs": [],
   "source": [
    "f= open(\"development.linebyline.txt\",\"w+\")\n",
    "for i in range(len(ID)):\n",
    "    f.write(ID[i])\n",
    "    f.write(\"\\t\")\n",
    "    f.write(Title1[i])\n",
    "    f.write(\"\\t\")\n",
    "    f.write(Paragraph[i])\n",
    "    f.write(\"\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pkhHQFOc1waB"
   },
   "outputs": [],
   "source": [
    "file= open(\"development.finallytagged.txt\",\"w+\")\n",
    "text= open(\"development.linebyline.txt\",\"r\")\n",
    "data=text.read()\n",
    "j=0\n",
    "for i in range(len(data)):\n",
    "    if data[i]==\"|\":\n",
    "        file.write(\" <\")\n",
    "        file.write(ndTags[j])\n",
    "        file.write(\"> \")\n",
    "        j=j+1\n",
    "        #if j==34381:\n",
    "        #  break;\n",
    "    else:\n",
    "        file.write(data[i])\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x2QSK9gR1wMq"
   },
   "outputs": [],
   "source": [
    "sort=open(\"sortted.annotation.txt\",\"w+\")\n",
    "i=0\n",
    "for i in range(len(ndend)-1):\n",
    "    if ndTitle[i]==ndTitle[i+1] and int(ndParaID[i])==int(ndParaID[i+1]):\n",
    "        if int(ndend[i])>int(ndend[i+1]):\n",
    "            sort.write(ndParaID[i])\n",
    "            sort.write(\"\\t\")\n",
    "            sort.write(ndnames[i])\n",
    "            sort.write(\"\\n\")\n",
    "sort.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zcWZH8Dz14Zf"
   },
   "outputs": [],
   "source": [
    "len(ndTags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VwO3C1EK15gc"
   },
   "outputs": [],
   "source": [
    "j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aCuSrOlS2Omf"
   },
   "source": [
    "### **Evaluation file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5MDKJLLs2TSx"
   },
   "outputs": [],
   "source": [
    "dataframe = pandas.read_csv(\"evaluation.abstracts.txt\",delimiter=\"\\t\")\n",
    "\n",
    "dataframe.to_csv(\"table.eval.abstracts.csv\", encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qvb-cSC02USE"
   },
   "outputs": [],
   "source": [
    "ID=[]\n",
    "Title1=[]\n",
    "Paragraph=[]\n",
    "import csv\n",
    "with open('table.eval.abstracts.csv','rt')as f:\n",
    "    data = csv.reader(f)\n",
    "    for row in data:\n",
    "        ID.append(row[0])\n",
    "        Title1.append(row[1])\n",
    "        Paragraph.append(row[2])\n",
    "        #print(row[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-h3M8akE3gBa"
   },
   "source": [
    "**Sort the paragraphs according to Paragraph ID**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8Q7EPoyd2Uwb"
   },
   "outputs": [],
   "source": [
    "def insertionSort(alist):\n",
    "    for index in range(1,len(alist)):\n",
    "\n",
    "        currentvalue = alist[index]\n",
    "        currentvalue1=Title1[index]\n",
    "        currentvalue2=Paragraph[index]\n",
    "        position = index\n",
    "\n",
    "        while position>0 and alist[position-1]>currentvalue:\n",
    "            alist[position]=alist[position-1]\n",
    "            Title1[position]=Title1[position-1]\n",
    "            Paragraph[position]=Paragraph[position-1]\n",
    "            position = position-1\n",
    "\n",
    "        alist[position]=currentvalue\n",
    "        Title1[position]=currentvalue1\n",
    "        Paragraph[position]=currentvalue2\n",
    "\n",
    "alist = ID\n",
    "insertionSort(alist)\n",
    "print(ID)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TJsNBHsD2UtL"
   },
   "outputs": [],
   "source": [
    "file= open(\"evaluation.abstracts.sort.txt\",\"w+\")\n",
    "for i in range(len(ID)):\n",
    "    file.write(ID[i])\n",
    "    file.write(\"\\t\")\n",
    "    file.write(Title1[i])\n",
    "    file.write(\"\\t\")\n",
    "    file.write(Paragraph[i])\n",
    "    file.write(\"\\n\")\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GagFhY262Unt"
   },
   "outputs": [],
   "source": [
    "dataframe = pandas.read_csv(\"evaluation.annotations.txt\",delimiter=\"\\t\")\n",
    "\n",
    "\n",
    "\n",
    "dataframe.to_csv(\"table.evaluation.annotations.csv\", encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ziOr9pjK2UmO"
   },
   "outputs": [],
   "source": [
    "eParaID=[]\n",
    "eTitle=[]\n",
    "estart=[]\n",
    "eend=[]\n",
    "enames=[]\n",
    "eTags=[]\n",
    "import csv\n",
    "with open('table.evaluation.annotations.csv','rt')as f:\n",
    "    data = csv.reader(f)\n",
    "    for row in data:\n",
    "        eParaID.append(row[0])\n",
    "        eTitle.append(row[1])\n",
    "        estart.append(row[2])\n",
    "        eend.append(row[3])\n",
    "        enames.append(row[4])\n",
    "        eTags.append(row[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G7EOnOvr2Ukq"
   },
   "outputs": [],
   "source": [
    "def insertionSort(alist):\n",
    "    for index in range(1,len(alist)):\n",
    "\n",
    "        currentvalue = alist[index]\n",
    "        currentvalue1=eTitle[index]\n",
    "        currentvalue2=estart[index]\n",
    "        currentvalue3=eend[index]\n",
    "        currentvalue4=enames[index]\n",
    "        currentvalue5=eTags[index]\n",
    "      \n",
    "        position = index\n",
    "\n",
    "        while position>0 and alist[position-1]>currentvalue:\n",
    "            alist[position]=alist[position-1]\n",
    "            eTitle[position]=eTitle[position-1]\n",
    "            estart[position]=estart[position-1]\n",
    "            eend[position]=eend[position-1]\n",
    "            enames[position]=enames[position-1]\n",
    "            eTags[position]=eTags[position-1]\n",
    "            position = position-1\n",
    "\n",
    "        alist[position]=currentvalue\n",
    "        eTitle[position]=currentvalue1\n",
    "        estart[position]=currentvalue2\n",
    "        eend[position]=currentvalue3\n",
    "        enames[position]=currentvalue4\n",
    "        eTags[position]=currentvalue5\n",
    "\n",
    "alist = eParaID\n",
    "insertionSort(alist)\n",
    "#print(alist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LltnjLBT2UjA"
   },
   "outputs": [],
   "source": [
    "file= open(\"evaluation.annotations.sort.txt\",\"w+\")\n",
    "for i in range(len(eParaID)):\n",
    "    file.write(eParaID[i])\n",
    "    file.write(\"\\t\")\n",
    "    file.write(eTitle[i])\n",
    "    file.write(\"\\t\")\n",
    "    file.write(estart[i])\n",
    "    file.write(\"\\t\")\n",
    "    file.write(eend[i])\n",
    "    file.write(\"\\t\")\n",
    "    file.write(enames[i])\n",
    "    file.write(\"\\t\")\n",
    "    file.write(eTags[i])\n",
    "    file.write(\"\\n\")\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1tybYhnk4N_f"
   },
   "source": [
    "**Tokenize the text** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "14i5H8dh2UgI"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "f= open(\"evaluation25.txt\",\"w+\")\n",
    "for i in range(len(enames)):\n",
    "    strc=enames[i]\n",
    "    strt=eTags[i]\n",
    "    b=int(estart[i])\n",
    "    # c=int(tend[i])\n",
    "    count=0\n",
    "    for j in range(len(strc)):\n",
    "        if strc[j]==\" \":\n",
    "            count=count+1\n",
    "    if count==0:\n",
    "        r=eParaID[i]+\"\\t\"+eTitle[i]+\"\\t\"+estart[i]+\"\\t\"+eend[i]+\"\\t\"+strc+\"\\tB-\"+strt+\"\\n\"\n",
    "        f.write(r)\n",
    "    if count>0:\n",
    "        #nltk_tokens = nltk.word_tokenize(str)\n",
    "        nltk_tokens=WhitespaceTokenizer().tokenize(strc)\n",
    "        for k in range(len(nltk_tokens)):\n",
    "            if(k==0):\n",
    "                c=b+len(nltk_tokens[0])\n",
    "                r=eParaID[i]+\"\\t\"+eTitle[i]+\"\\t\"\n",
    "                f.write(r)\n",
    "                r=str(b)\n",
    "                f.write(r)\n",
    "                r=\"\\t\"\n",
    "                f.write(r)\n",
    "                r=str(c)\n",
    "                f.write(r)\n",
    "                r=\"\\t\"+nltk_tokens[0]+\"\\tB-\"+strt+\"\\n\"\n",
    "                b=c+1\n",
    "                f.write(r)\n",
    "            else:\n",
    "                c=b+len(nltk_tokens[k])\n",
    "                r=eParaID[i]+\"\\t\"+eTitle[i]+\"\\t\"\n",
    "                f.write(r)\n",
    "                r=str(b)\n",
    "                f.write(r)\n",
    "                r=\"\\t\"\n",
    "                f.write(r)\n",
    "                r=str(c)\n",
    "                f.write(r)\n",
    "                r=\"\\t\"+nltk_tokens[k]+\"\\tI-\"+strt+\"\\n\"\n",
    "                b=c+1\n",
    "                f.write(r)\n",
    "        \n",
    "f.close()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6BLGsNAy2Udf"
   },
   "outputs": [],
   "source": [
    "dataframe = pandas.read_csv(\"evaluation25.txt\",delimiter=\"\\t\")\n",
    "\n",
    "\n",
    "dataframe.to_csv(\"table.evaluation25.csv\", encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IO7wY2uK2UZy"
   },
   "outputs": [],
   "source": [
    "neParaID=[]\n",
    "neTitle=[]\n",
    "nestart=[]\n",
    "neend=[]\n",
    "nenames=[]\n",
    "neTags=[]\n",
    "import csv\n",
    "with open('table.evaluation25.csv','rt')as f:\n",
    "    data = csv.reader(f)\n",
    "    for row in data:\n",
    "        neParaID.append(row[0])\n",
    "        neTitle.append(row[1])\n",
    "        nestart.append(row[2])\n",
    "        neend.append(row[3])\n",
    "        nenames.append(row[4])\n",
    "        neTags.append(row[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TYC40aP02UV8"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Python Program to search an element \n",
    "# in a sorted and pivoted array \n",
    "  \n",
    "# Searches an element key in a pivoted \n",
    "# sorted array arrp[] of size n  \n",
    "def pivotedBinarySearch(arr, n, key): \n",
    "  \n",
    "    pivot = findPivot(arr, 0, n-1); \n",
    "  \n",
    "    # If we didn't find a pivot,  \n",
    "    # then array is not rotated at all \n",
    "    if pivot == -1: \n",
    "        return binarySearch(arr, 0, n-1, key); \n",
    "  \n",
    "    # If we found a pivot, then first \n",
    "    # compare with pivot and then \n",
    "    # search in two subarrays around pivot \n",
    "    if arr[pivot] == key: \n",
    "        return pivot \n",
    "    if arr[0] <= key: \n",
    "        return binarySearch(arr, 0, pivot-1, key); \n",
    "    return binarySearch(arr, pivot+1, n-1, key); \n",
    "  \n",
    "# Function to get pivot.\n",
    "# For array  3, 4, 5, 6, 1, 2 it returns 3  (index of 6)  \n",
    "def findPivot(arr, low, high): \n",
    "      \n",
    "    # base cases \n",
    "    if high < low: \n",
    "        return -1\n",
    "    if high == low: \n",
    "        return low \n",
    "      \n",
    "    #low + (high - low)/2; \n",
    "    mid = int((low + high)/2) \n",
    "      \n",
    "    if mid < high and arr[mid] > arr[mid + 1]: \n",
    "        return mid \n",
    "    if mid > low and arr[mid] < arr[mid - 1]: \n",
    "        return (mid-1) \n",
    "    if arr[low] >= arr[mid]: \n",
    "        return findPivot(arr, low, mid-1) \n",
    "    return findPivot(arr, mid + 1, high) \n",
    "  \n",
    "# Standard Binary Search function*/ \n",
    "def binarySearch(arr, low, high, key): \n",
    "  \n",
    "    if high < low: \n",
    "        return -1\n",
    "          \n",
    "    #low + (high - low)/2;     \n",
    "    mid = int((low + high)/2) \n",
    "      \n",
    "    if key == arr[mid]: \n",
    "        return mid\n",
    "    if key > arr[mid]: \n",
    "        return binarySearch(arr, (mid + 1), high, \n",
    "                                            key); \n",
    "    return binarySearch(arr, low, (mid -1), key);\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "# Driver program to check above functions */\n",
    "# Let us search 3 in below array \n",
    "arr1=ID \n",
    "n = len(arr1) \n",
    "#f= open(\"training.linebyline.txt\",\"w+\")\n",
    "for i in range(len(neParaID)):\n",
    "    a=pivotedBinarySearch(arr1, n, neParaID[i])\n",
    "    if neTitle[i]=='T':\n",
    "        b=int(neend[i])\n",
    "        strt=Title1[a]\n",
    "        strt=strt[:b]+\"|\"+strt[b+1:]\n",
    "        Title1[a]=strt\n",
    "        #f.write(Title1[a]) \n",
    "    else:\n",
    "        b=int(neend[i])\n",
    "        strt=Paragraph[a]\n",
    "        strt=strt[:b]+\"|\"+strt[b+1:]\n",
    "        Paragraph[a]=strt\n",
    "        #f.write(Paragraph[a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4axXglzv2UQK"
   },
   "outputs": [],
   "source": [
    "f= open(\"evaluation.linebyline.txt\",\"w+\")\n",
    "for i in range(len(ID)):\n",
    "    f.write(ID[i])\n",
    "    f.write(\"\\t\")\n",
    "    f.write(Title1[i])\n",
    "    f.write(\"\\t\")\n",
    "    f.write(Paragraph[i])\n",
    "    f.write(\"\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ChmPLRYj2UOq"
   },
   "outputs": [],
   "source": [
    "file= open(\"evaluation.finallytagged.txt\",\"w+\")\n",
    "text= open(\"evaluation.linebyline.txt\",\"r\")\n",
    "data=text.read()\n",
    "j=0\n",
    "for i in range(len(data)):\n",
    "    if data[i]==\"|\":\n",
    "        file.write(\" <\")\n",
    "        file.write(neTags[j])\n",
    "        file.write(\"> \")\n",
    "        j=j+1\n",
    "    else:\n",
    "        file.write(data[i])\n",
    "file.close()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Untitled7.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
